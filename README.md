## ‚ö° Previs√£o de Consumo de Energia com Redes Neurais Recorrentes (LSTM)

Este projeto utiliza uma rede neural Long Short-Term Memory (LSTM) para prever o consumo de energia de eletrodom√©sticos. O modelo foi treinado com o dataset "Appliances Energy Prediction" (ID 374) do UCI Machine Learning Repository, que fornece dados temporais e vari√°veis ambientais. A abordagem LSTM √© ideal para capturar as depend√™ncias sequenciais complexas no consumo de energia, oferecendo previs√µes de alta precis√£o.

O ponto crucial deste trabalho reside na **metodologia rigorosa de pr√©-processamento** para garantir que o modelo n√£o sofra com **"data leakage" (vazamento de dados)**, uma falha comum em problemas de s√©ries temporais.

---

### üîë Destaques e Metodologia Rigorosa

#### 1. Preven√ß√£o de Data Leakage no Escalonamento
Para manter a integridade temporal do treino e teste:
* O conjunto de dados foi dividido em treino e teste (80/20) **respeitando a ordem cronol√≥gica**.
* O `MinMaxScaler` do target (`scaler_target`) foi **ajustado (`fit`) exclusivamente nos dados de treino** da coluna `Appliances`.
* **Revers√£o Cr√≠tica:** As m√©tricas (RMSE e MAE) e o gr√°fico comparativo s√£o gerados **somente ap√≥s reverter as previs√µes** para a escala original (Watts) usando o `scaler_target`, garantindo interpretabilidade.

#### 2. Configura√ß√£o da Janela Temporal (Sliding Window)
* **Granularidade:** Os dados foram coletados a cada **10 minutos**.
* **`LOOK_BACK` (Janela de Observa√ß√£o):** Foi definido como **60 passos**, o que significa que o modelo utiliza **10 horas** de dados hist√≥ricos (60 passos x 10 min/passo) para fazer a pr√≥xima previs√£o. Isso √© crucial para capturar padr√µes de consumo di√°rios.
* **Dimensionalidade:** Os dados de treino para a LSTM t√™m o formato: **(15728 amostras, 60 passos, 7 features)**.

#### 3. Ambiente e Treinamento
* **Acelera√ß√£o:** O notebook foi configurado para utilizar **GPU (T4)**, o que √© ideal para o treinamento de Redes Neurais Profundas como a LSTM.
* **Target e Features:** O alvo da previs√£o √© `Appliances` e o conjunto de features inclui temperaturas internas/externas (`T1`, `RH_1`, `T_out`), press√£o (`Press_mm_hg`), velocidade do vento (`Windspeed`) e consumo de luzes (`lights`).

---

### üìâ Resultados e M√©tricas de Desempenho

As m√©tricas foram calculadas na **escala original (Watts)**, revertidas pelo `scaler_target`.

| M√©trica | Valor | Interpreta√ß√£o |
| :--- | :--- | :--- |
| **RMSE** | **57.47 Watts** | O desvio padr√£o dos erros de previs√£o (na mesma unidade do target). |
| **MAE** | **25.92 Watts** | O erro absoluto m√©dio das previs√µes. O modelo erra, em m√©dia, ~26 Watts. |
| **Test Loss (MSE Escal.)** | **0.002885** | O valor de perda do modelo na escala `[0, 1]` no conjunto de teste. |

---

### üìä Gr√°fico de Compara√ß√£o (Valores Reais vs. Previstos)

O gr√°fico abaixo mostra um trecho das previs√µes no conjunto de teste, revertidas para a escala original (Watts), demonstrando a ader√™ncia do modelo √† s√©rie temporal.

<img width="1266" height="630" alt="image" src="https://github.com/user-attachments/assets/7183f046-28c3-40fa-9c27-cae3d3fb9013" />

---

### üöÄ Como Rodar o Projeto

1.  Clone este reposit√≥rio.
2.  Abra o arquivo `RNN.ipynb` em um ambiente Jupyter (como Google Colab ou VS Code).
3.  Execute as c√©lulas em ordem. O download dos dados e a instala√ß√£o das depend√™ncias (como `tensorflow.keras`) ser√£o tratados automaticamente pelo notebook.
